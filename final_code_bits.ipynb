{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikarthik952/Bits-Final-Project/blob/main/final_code_bits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn6Uo5lRrkuU",
        "outputId": "b6637310-c389-4591-a645-e96bc71ad3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (24.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (1.25.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jaxlib) (0.2.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.32.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.42)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.615s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install faker\n",
        "!pip install jaxlib\n",
        "!pip install streamlit\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWdzArc4rHKu"
      },
      "outputs": [],
      "source": [
        "# for command line usage\n",
        "import sys, getopt\n",
        "\n",
        "\n",
        "# for creating fake values\n",
        "from faker import Faker\n",
        "# for random sampling\n",
        "from numpy.random import choice as choose\n",
        "from numpy.random import seed as setseed\n",
        "# for progress bar\n",
        "from tqdm import tqdm\n",
        "# for generating file name with current time\n",
        "from datetime import datetime\n",
        "# for saving the final dataframe.\n",
        "import pandas as pd\n",
        "from faker.providers import BaseProvider\n",
        "import random\n",
        "import string\n",
        "\n",
        "class CustomProvider(BaseProvider):\n",
        "    def random_12_digits(self):\n",
        "        return ''.join(str(random.randint(0, 9)) for _ in range(12))\n",
        "    def custom_pattern_string(self):\n",
        "        uppercase_letters = ''.join(random.choice(string.ascii_uppercase) for _ in range(5))\n",
        "        digits = ''.join(random.choice(string.digits) for _ in range(4))\n",
        "        last_char = random.choice(string.ascii_uppercase)\n",
        "        return str(uppercase_letters + digits + last_char)\n",
        "    def random_txn_id(self, length=10):\n",
        "        return ''.join('pay_' + random.choice(string.ascii_uppercase + string.digits) for _ in range(length))\n",
        "    def custom_paragraph_with_keywords(self, keyword_list, num_sentences=1):\n",
        "        sentences = []\n",
        "\n",
        "        # Predefined sentences with keywords\n",
        "        predefined_sentences = [\n",
        "            \"Transaction is successful for   {} Payment\",\n",
        "            \"Customer  Identity with {}.\",\n",
        "            \"Payment for  {}.\",\n",
        "            \"{} value for customer\",\n",
        "             \"A payment of {} with  was successfully processed.\",\n",
        "    \"Your recent transaction of {} with has been confirmed.\",\n",
        "    \"Thank you for your payment of {} with on our platform.\",\n",
        "    \"A withdrawal of {} witj has been completed from your account.\",\n",
        "    \"The payment of {} with was successful.\",\n",
        "    \"Your credit card associated with {} has been charged\",\n",
        "    \"A refund of {} with has been initiated for your recent transaction.\",\n",
        "    \"A payment of {} with was declined. Please check your payment information.\",\n",
        "    \"Your account has been credited with {} with for a successful transaction.\",\n",
        "    \"{} with has been transferred to your linked bank account.\",\n",
        "            \"This is a sample sentence that doesn't contain anything\",\n",
        "            \"[\\\"IdCard\\\":\\\"{}\\\", \\\"message\\\":\\\"This is ID card\\\"]\"\n",
        "        ]\n",
        "\n",
        "        for _ in range(num_sentences):\n",
        "\n",
        "                # Use a predefined sentence with a keyword\n",
        "              sentence_template = random.choice(predefined_sentences)\n",
        "              keyword = random.choice(keyword_list)\n",
        "              sentence = sentence_template.format(keyword)\n",
        "              sentences.append(sentence)\n",
        "\n",
        "        return ' '.join(sentences)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sep_change(text, init_sep, after_sep):\n",
        "    \"\"\"\n",
        "    A function to separate the input text into strings by the init_sep variable\n",
        "\n",
        "    and combine the strings again by the after_sep variable.\n",
        "    \"\"\"\n",
        "    splitted_strings = text.split(init_sep)\n",
        "\n",
        "    combined_strings = after_sep.join(splitted_strings)\n",
        "\n",
        "    return combined_strings\n",
        "\n",
        "def convert_datetime_underscore(data):\n",
        "    \"\"\"\n",
        "    A Helper function to convert all separators in datetime.now() into underscore.\n",
        "    \"\"\"\n",
        "    now_string = str(data)\n",
        "\n",
        "    now_string = sep_change(now_string, init_sep = \"-\", after_sep = \"_\")\n",
        "\n",
        "    now_string = sep_change(now_string, init_sep = \" \", after_sep = \"_\")\n",
        "\n",
        "    now_string = sep_change(now_string, init_sep = \":\", after_sep = \"_\")\n",
        "\n",
        "    now_string = sep_change(now_string, init_sep = \".\", after_sep = \"_\")\n",
        "\n",
        "    return now_string\n",
        "\n",
        "def _random_sep_change(data, init_sep = \"-\", after_sep = \" \", percentage = 0.5 , seed = 7):\n",
        "    \"\"\"\n",
        "    A function to randomly change the SSN data's separator.\n",
        "\n",
        "    The input data is a list.\n",
        "    \"\"\"\n",
        "    setseed(seed)\n",
        "    # generate the index for replacing separator.\n",
        "    replacing_indexes = choose(range(len(data)), int(len(data)*percentage))\n",
        "\n",
        "    for each_replacing_index in replacing_indexes:\n",
        "        # change the ssn data's separator from init_sep to after_sep\n",
        "        data[each_replacing_index] = sep_change(data[each_replacing_index], init_sep, after_sep)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Fake_PII():\n",
        "    '''\n",
        "    A class to generate a number of fake profiles, training/testing text mixed with\n",
        "    different types of fake PIIs.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    fake_ = Fake_PII()\n",
        "    fake_.create_fake_profile(10)\n",
        "    train_labels, train_text, train_PII = fake_.create_pii_text_train(n_text = 5)\n",
        "    '''\n",
        "    def __init__(self, n_profile = None,fake_profiles = None, seed = 7,\\\n",
        "                pii_with_text = None, pii_labels = None, PII = None):\n",
        "\n",
        "\n",
        "\n",
        "        # initialize the Faker from faker package for fake data generation.\n",
        "        try:\n",
        "            self.faker = Faker()\n",
        "        except ImportError as error:\n",
        "            print(error.__class__.__name__ + \": \" + error.message)\n",
        "\n",
        "        self.faker.add_provider(CustomProvider)\n",
        "        self.n_profile = n_profile\n",
        "        self.pii_with_text = pii_with_text\n",
        "        self.pii_labels = pii_labels\n",
        "        self.fake_profiles = fake_profiles\n",
        "        self.seed = seed\n",
        "        self.PII = PII\n",
        "\n",
        "\n",
        "    def create_fake_profile(self, n_profile, verbose = False, ssn_sep_change = True):\n",
        "\n",
        "        assert isinstance(n_profile, int), \"Please enter an integer\\\n",
        "        for the number of generated profiles.\"\n",
        "        self.n_profile = n_profile\n",
        "\n",
        "        fake_profiles = dict()\n",
        "\n",
        "\n",
        "        fake_profiles[\"Aadhaar\"] = [self.faker.random_12_digits() for _ in range(self.n_profile)]\n",
        "\n",
        "        fake_profiles[\"Other\"] = [self.faker.random_txn_id() for _ in range(self.n_profile)]\n",
        "\n",
        "\n",
        "\n",
        "        fake_profiles[\"Pancard\"] = [self.faker.custom_pattern_string()\\\n",
        "                                   for _ in range(self.n_profile)]\n",
        "\n",
        "        self.fake_profiles = fake_profiles\n",
        "\n",
        "        if verbose:\n",
        "            return self.fake_profiles\n",
        "\n",
        "    def _init_pii_gen_train(self):\n",
        "\n",
        "        # generate the all possible PII implemented in the create_fake_profile methods\n",
        "        self._fake_labels = list(self.fake_profiles.keys())\n",
        "        # print(self._fake_labels);\n",
        "        # print(\"1\")\n",
        "        # generate the None labels\n",
        "        self._none_pii_labels = [\"Other\" for _ in range(self._n_text)]\n",
        "        # print(self._none_pii_labels);\n",
        "        # print(\"2\")\n",
        "        # generate the pii labels\n",
        "        self.pii_labels = sorted(self._fake_labels*self._n_text)\n",
        "        # print(self.pii_labels);\n",
        "        # print(\"3\")\n",
        "        # generate the test with no pii\n",
        "        self._fake_text_no_pii = [self.faker.custom_paragraph_with_keywords(keyword_list=['aadhaar','pancard']) for _ in range(self._n_text)]\n",
        "        # print(self._fake_text_no_pii);\n",
        "        # print(\"4\")\n",
        "        # mutiply the no pii text with the number of PII types\n",
        "        self._init_fake_text_no_pii = self._fake_text_no_pii*len(self._fake_labels)\n",
        "        # print(self._init_fake_text_no_pii);\n",
        "        # print(\"5\")\n",
        "\n",
        "        # initialize the text mixed with PII with all \"None\" strings.\n",
        "        self.pii_with_text = [\"None\" for _ in range(len(self._fake_labels)*(self._n_text))]\n",
        "        # print(self.pii_with_text);\n",
        "        # print(\"6\")\n",
        "        # initialize the PII with all \"None\" strings\n",
        "        self.PII = [\"None\" for _ in range(self._n_text*(len(self._fake_labels)+1))]\n",
        "        # print(self.PII);\n",
        "        # print(\"7\")\n",
        "    def _random_pii_insert(self):\n",
        "        # randomly insert PII into the text\n",
        "        for index, PII in enumerate(tqdm(self.pii_labels)):\n",
        "            # choose a PII value from the dictionary according to the PII type.\n",
        "            #print(\"PII\" + PII)\n",
        "            PII_value = choose(self.fake_profiles[PII])\n",
        "            #print(\"PIIval\" + PII_value)\n",
        "            if PII == \"Other\" :\n",
        "               original_fake_text = self.faker.custom_paragraph_with_keywords(keyword_list=[str(\"TxnId\" + \" - \" + PII_value)])\n",
        "            else :\n",
        "               original_fake_text = self.faker.custom_paragraph_with_keywords(keyword_list=[str(PII + \" - \" + PII_value)])\n",
        "\n",
        "            # tokenized_fake_text = original_fake_text.split(\" \")\n",
        "\n",
        "            # # generate the position to fill in the PII value\n",
        "            # PII_position = choose(range(len(tokenized_fake_text)+1))\n",
        "\n",
        "            # tokenized_fake_text.insert(PII_position, PII_value)\n",
        "\n",
        "            # one_text_mixed_with_PII = \" \".join(tokenized_fake_text)\n",
        "\n",
        "            self.pii_with_text[index] = original_fake_text\n",
        "            self.PII[index] = PII_value\n",
        "\n",
        "\n",
        "    def create_pii_text_train(self, n_text = 10):\n",
        "        \"\"\"\n",
        "        A method to create the training text randomly mixed with fake PII. This\n",
        "        method creates a text and mixed it with different kinds of PII, which leads\n",
        "        to a total number of (num_of_PII)*(n_text) rows.\n",
        "\n",
        "        \"\"\"\n",
        "        warning_text = \"Please create fake profiles first with .create_fake_profile method.\"\n",
        "        assert self.fake_profiles is not None, warning_text\n",
        "\n",
        "        self._n_text = n_text\n",
        "        # initialized a few variables for inserting PII values\n",
        "        self._init_pii_gen_train()\n",
        "\n",
        "        # randomly insert Pii text into the paragraph.\n",
        "        self._random_pii_insert()\n",
        "\n",
        "\n",
        "        self.pii_with_text.extend(self._fake_text_no_pii)\n",
        "        self.pii_labels.extend(self._none_pii_labels)\n",
        "\n",
        "\n",
        "\n",
        "        return self.pii_labels, self.pii_with_text, self.PII\n",
        "\n",
        "    def _init_pii_gen_test(self):\n",
        "\n",
        "        # generate the all possible PII implemented in the create_fake_profile methods\n",
        "        self._fake_labels = list(self.fake_profiles.keys())\n",
        "\n",
        "        # generate the None labels\n",
        "        self._none_pii_labels = [\"Other\" for _ in range(self._n_text)]\n",
        "\n",
        "        # generate the pii labels\n",
        "        self.pii_labels = sorted(self._fake_labels)\n",
        "\n",
        "        total_num_pii_text = (1+len(self._fake_labels))\n",
        "        # generate the fake text with no pii\n",
        "        self._init_fake_text_no_pii = [self.faker.custom_paragraph_with_keywords(keyword_list=['aadhaar','pancard']) for _ in range(total_num_pii_text)]\n",
        "\n",
        "        # initialize the text mixed with PII with all \"None\" strings.\n",
        "        self.pii_with_text = self._init_fake_text_no_pii\n",
        "        # initialize the PII with all \"None\" strings\n",
        "        self.PII = [\"None\" for _ in range(total_num_pii_text)]\n",
        "\n",
        "\n",
        "    def create_pii_text_test(self, n_text = 10):\n",
        "        \"\"\"\n",
        "        A method to create the testing text randomly mixed with fake PII.\n",
        "        This method creates a text and mixed it with a type of PII.\n",
        "\n",
        "        In the training text, a normal text is repeated used to insert different PIIs into\n",
        "        it. In the testing text, a normal text is not intentionally repeated to insert\n",
        "        different PIIs.\n",
        "\n",
        "        \"\"\"\n",
        "        warning_text = \"Please create fake profiles first with .create_fake_profile method.\"\n",
        "        assert self.fake_profiles is not None, warning_text\n",
        "\n",
        "        self._n_text = n_text\n",
        "\n",
        "        # initialized a few variables for inserting PII values\n",
        "        self._init_pii_gen_test()\n",
        "\n",
        "        # randomly insert Pii text into the paragraph.\n",
        "        self._random_pii_insert()\n",
        "        # add the none labels\n",
        "        #self.pii_labels.extend(self._none_pii_labels)\n",
        "\n",
        "        return self.pii_labels, self.pii_with_text, self.PII\n",
        "\n",
        "\n",
        "\n",
        "def write_to_disk_train(requested_train_data_size):\n",
        "\n",
        "    fake_ = Fake_PII()\n",
        "    fake_.create_fake_profile(requested_train_data_size)\n",
        "    train_labels, train_text, train_PII = fake_.create_pii_text_train(n_text = requested_train_data_size)\n",
        "\n",
        "    # save training data to disk\n",
        "    train_text_with_pii = pd.DataFrame({\"Text\":train_text, \"Labels\":train_labels, \"PII\":train_PII})\n",
        "    train_file_name = \"train_text_with_pii_\" + convert_datetime_underscore(datetime.now()) + \".csv\"\n",
        "    train_text_with_pii.to_csv(train_file_name,index=False)\n",
        "\n",
        "def write_to_disk_test(requested_test_data_size):\n",
        "    fake_ = Fake_PII()\n",
        "    fake_.create_fake_profile(requested_test_data_size)\n",
        "    test_labels, test_text, test_PII = fake_.create_pii_text_test(n_text = requested_test_data_size)\n",
        "\n",
        "    # save testing data to disk\n",
        "    test_text_with_pii = pd.DataFrame({\"Text\":test_text, \"Labels\":test_labels, \"PII\":test_PII})\n",
        "    test_file_name = \"test_text_with_pii_\" + convert_datetime_underscore(datetime.now()) + \".csv\"\n",
        "    test_text_with_pii.to_csv(test_file_name,index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    argument_list = sys.argv[1:]\n",
        "\n",
        "    if \"-train\" in argument_list:\n",
        "        train_value_index = argument_list.index(\"-train\") + 1\n",
        "        requested_train_data_size = int(argument_list[train_value_index])\n",
        "\n",
        "        write_to_disk_train(requested_train_data_size)\n",
        "\n",
        "    if \"-test\" in argument_list:\n",
        "        test_value_index = argument_list.index(\"-test\") + 1\n",
        "        requested_test_data_size = int(argument_list[test_value_index])\n",
        "\n",
        "        write_to_disk_test(requested_test_data_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChmsXMPmrLbD",
        "outputId": "e1d1abae-bf1c-4441-cc8c-3b911565133a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:00<00:00, 10107.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'PII', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
            "[\"This is a sample sentence that doesn't contain anything\", 'Aadhaar - 245305408565 value for customer', 'Thank you for your payment of Aadhaar - 163535239514 with on our platform.', 'Aadhaar - 951069542219 with has been transferred to your linked bank account.', 'A withdrawal of Aadhaar - 006558100054 witj has been completed from your account.', 'The payment of Aadhaar - 757267350918 with was successful.', 'A withdrawal of Aadhaar - 040169356874 witj has been completed from your account.', 'A refund of Aadhaar - 659570810275 with has been initiated for your recent transaction.', 'Aadhaar - 272070156403 value for customer', 'A refund of Aadhaar - 189478304954 with has been initiated for your recent transaction.', 'Aadhaar - 056745090399 value for customer', 'Your recent transaction of Aadhaar - 473995216470 with has been confirmed.', 'Aadhaar - 279930153992 value for customer', \"This is a sample sentence that doesn't contain anything\", 'Your account has been credited with Aadhaar - 617876456949 with for a successful transaction.', 'A refund of Aadhaar - 951069542219 with has been initiated for your recent transaction.', 'A refund of Aadhaar - 759969645667 with has been initiated for your recent transaction.', \"This is a sample sentence that doesn't contain anything\", 'Your credit card associated with Aadhaar - 053826108247 has been charged', 'A payment of Aadhaar - 163746400979 with was declined. Please check your payment information.', 'Your account has been credited with Aadhaar - 898518679267 with for a successful transaction.', 'A payment of Aadhaar - 753051834914 with was declined. Please check your payment information.', '[\"IdCard\":\"Aadhaar - 041890409687\", \"message\":\"This is ID card\"]', 'A payment of Aadhaar - 006558100054 with was declined. Please check your payment information.', 'Your credit card associated with Aadhaar - 040169356874 has been charged', 'Aadhaar - 965438428080 with has been transferred to your linked bank account.', 'Customer  Identity with Aadhaar - 579258430618.', 'A payment of Aadhaar - 970199177698 with was declined. Please check your payment information.', '[\"IdCard\":\"Aadhaar - 544256902836\", \"message\":\"This is ID card\"]', 'Payment for  Aadhaar - 694975789293.', 'Transaction is successful for   Aadhaar - 061898529654 Payment', 'Aadhaar - 753051834914 with has been transferred to your linked bank account.', 'A withdrawal of Aadhaar - 189478304954 witj has been completed from your account.', 'A withdrawal of Aadhaar - 370932388994 witj has been completed from your account.', 'Your credit card associated with Aadhaar - 747364494365 has been charged', 'Thank you for your payment of Aadhaar - 633722613065 with on our platform.', 'Aadhaar - 844251250207 with has been transferred to your linked bank account.', 'Aadhaar - 544256902836 with has been transferred to your linked bank account.', \"This is a sample sentence that doesn't contain anything\", 'The payment of Aadhaar - 933520977398 with was successful.', 'The payment of Aadhaar - 053826108247 with was successful.', 'A refund of Aadhaar - 370932388994 with has been initiated for your recent transaction.', 'Your credit card associated with Aadhaar - 189478304954 has been charged', 'Payment for  Aadhaar - 831262153393.', 'Transaction is successful for   Aadhaar - 753051834914 Payment', 'Your credit card associated with Aadhaar - 506929123020 has been charged', 'Thank you for your payment of Aadhaar - 277870639977 with on our platform.', 'A refund of Aadhaar - 853890926126 with has been initiated for your recent transaction.', 'Transaction is successful for   Aadhaar - 524717252485 Payment', 'Aadhaar - 685988120650 value for customer', 'Aadhaar - 513583102881 value for customer', 'The payment of Aadhaar - 053826108247 with was successful.', 'The payment of Aadhaar - 045746375137 with was successful.', 'Your credit card associated with Aadhaar - 992570017394 has been charged', 'Your credit card associated with Aadhaar - 797363744822 has been charged', 'Aadhaar - 170936389018 value for customer', 'Aadhaar - 006558100054 value for customer', 'Payment for  Aadhaar - 903050016469.', '[\"IdCard\":\"Aadhaar - 757267350918\", \"message\":\"This is ID card\"]', 'Transaction is successful for   Aadhaar - 100212849209 Payment', 'Aadhaar - 282275206888 with has been transferred to your linked bank account.', 'Aadhaar - 437789283396 with has been transferred to your linked bank account.', 'Thank you for your payment of Aadhaar - 627784150213 with on our platform.', 'Customer  Identity with Aadhaar - 544711972165.', 'Aadhaar - 797363744822 with has been transferred to your linked bank account.', 'Transaction is successful for   Aadhaar - 844251250207 Payment', 'A payment of Aadhaar - 559027355091 with  was successfully processed.', 'A refund of Aadhaar - 797363744822 with has been initiated for your recent transaction.', 'Aadhaar - 452447415802 with has been transferred to your linked bank account.', 'Thank you for your payment of Aadhaar - 277870639977 with on our platform.', 'Transaction is successful for   Aadhaar - 120969773372 Payment', 'Transaction is successful for   Aadhaar - 279930153992 Payment', 'The payment of Aadhaar - 491577364220 with was successful.', 'A payment of Aadhaar - 524717252485 with was declined. Please check your payment information.', 'Your credit card associated with Aadhaar - 605234610007 has been charged', \"This is a sample sentence that doesn't contain anything\", 'Aadhaar - 437789283396 value for customer', 'Aadhaar - 514834794884 value for customer', 'The payment of Aadhaar - 957572407421 with was successful.', 'Your credit card associated with Aadhaar - 041890409687 has been charged', 'Payment for  Aadhaar - 070315937070.', 'Customer  Identity with Aadhaar - 965438428080.', 'Transaction is successful for   Aadhaar - 294455844602 Payment', 'A payment of Aadhaar - 544711972165 with was declined. Please check your payment information.', 'Thank you for your payment of Aadhaar - 559027355091 with on our platform.', 'Customer  Identity with Aadhaar - 247548236221.', 'Thank you for your payment of Aadhaar - 437789283396 with on our platform.', 'Payment for  Aadhaar - 975210172288.', 'Your account has been credited with Aadhaar - 287614794573 with for a successful transaction.', 'A payment of Aadhaar - 120514924235 with  was successfully processed.', 'The payment of Aadhaar - 284067236232 with was successful.', 'Your credit card associated with Aadhaar - 277870639977 has been charged', 'Thank you for your payment of Aadhaar - 301690130441 with on our platform.', 'Aadhaar - 326503906842 with has been transferred to your linked bank account.', 'Your account has been credited with Aadhaar - 514834794884 with for a successful transaction.', 'Aadhaar - 579258430618 with has been transferred to your linked bank account.', 'Payment for  Aadhaar - 084445399817.', 'Thank you for your payment of Aadhaar - 831262153393 with on our platform.', '[\"IdCard\":\"Aadhaar - 472073193687\", \"message\":\"This is ID card\"]', 'Your credit card associated with Aadhaar - 513818685263 has been charged', 'A payment of TxnId - pay_Hpay_5pay_Wpay_Mpay_5pay_Gpay_7pay_Cpay_6pay_G with  was successfully processed.', 'A payment of TxnId - pay_Mpay_1pay_Hpay_Ypay_0pay_1pay_Tpay_Jpay_7pay_O with was declined. Please check your payment information.', 'TxnId - pay_Fpay_Epay_Wpay_3pay_Vpay_Epay_Dpay_8pay_4pay_4 value for customer', '[\"IdCard\":\"TxnId - pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J\", \"message\":\"This is ID card\"]', 'TxnId - pay_Gpay_Spay_Bpay_Ipay_Vpay_4pay_5pay_Ypay_Epay_6 with has been transferred to your linked bank account.', 'TxnId - pay_9pay_Ppay_Lpay_Vpay_Wpay_Upay_Rpay_0pay_Gpay_1 value for customer', 'Transaction is successful for   TxnId - pay_2pay_2pay_8pay_Rpay_Fpay_9pay_2pay_Ypay_Kpay_O Payment', 'Your account has been credited with TxnId - pay_Fpay_Fpay_Rpay_Gpay_Tpay_7pay_Ipay_Spay_Cpay_L with for a successful transaction.', 'Your credit card associated with TxnId - pay_Dpay_Cpay_Epay_Hpay_8pay_Xpay_9pay_Xpay_Dpay_2 has been charged', 'A refund of TxnId - pay_Rpay_Epay_Hpay_2pay_7pay_Rpay_Zpay_Lpay_Jpay_D with has been initiated for your recent transaction.', 'A payment of TxnId - pay_5pay_Rpay_3pay_Mpay_Npay_Qpay_Fpay_2pay_5pay_R with was declined. Please check your payment information.', 'A withdrawal of TxnId - pay_2pay_6pay_6pay_Hpay_Ypay_9pay_Dpay_Upay_Rpay_L witj has been completed from your account.', 'Thank you for your payment of TxnId - pay_Tpay_Gpay_Dpay_Ppay_Wpay_Gpay_Opay_Xpay_0pay_G with on our platform.', 'Your credit card associated with TxnId - pay_Jpay_Dpay_4pay_Qpay_Rpay_Cpay_Zpay_Xpay_Upay_V has been charged', 'A payment of TxnId - pay_Dpay_9pay_Vpay_Epay_5pay_Tpay_2pay_Spay_2pay_2 with  was successfully processed.', '[\"IdCard\":\"TxnId - pay_6pay_Upay_Ppay_Cpay_Dpay_1pay_3pay_7pay_Apay_0\", \"message\":\"This is ID card\"]', 'Your credit card associated with TxnId - pay_9pay_Qpay_Lpay_Spay_Lpay_Jpay_Qpay_Spay_Ypay_6 has been charged', 'A payment of TxnId - pay_Tpay_Zpay_Cpay_Rpay_3pay_0pay_Upay_4pay_0pay_U with  was successfully processed.', 'Thank you for your payment of TxnId - pay_4pay_Npay_Mpay_Dpay_2pay_6pay_Kpay_Bpay_Ipay_H with on our platform.', 'A withdrawal of TxnId - pay_1pay_Lpay_Apay_4pay_Zpay_Fpay_Tpay_6pay_4pay_N witj has been completed from your account.', \"This is a sample sentence that doesn't contain anything\", 'A withdrawal of TxnId - pay_Vpay_Mpay_Ipay_2pay_Zpay_6pay_Wpay_Xpay_Epay_H witj has been completed from your account.', 'Your credit card associated with TxnId - pay_3pay_3pay_Ppay_Hpay_Rpay_Upay_Ipay_Dpay_0pay_X has been charged', 'TxnId - pay_Ppay_Epay_Rpay_Npay_Lpay_2pay_4pay_Ppay_1pay_0 value for customer', 'TxnId - pay_Vpay_Wpay_Xpay_Opay_Ppay_Lpay_7pay_Spay_2pay_5 with has been transferred to your linked bank account.', 'A refund of TxnId - pay_7pay_7pay_Lpay_Npay_Jpay_Wpay_Opay_Jpay_Fpay_P with has been initiated for your recent transaction.', 'A withdrawal of TxnId - pay_6pay_Hpay_Opay_Hpay_Cpay_6pay_2pay_0pay_Qpay_Y witj has been completed from your account.', 'A payment of TxnId - pay_Mpay_1pay_Hpay_Ypay_0pay_1pay_Tpay_Jpay_7pay_O with  was successfully processed.', 'A payment of TxnId - pay_9pay_1pay_4pay_6pay_9pay_Mpay_Gpay_Zpay_Ipay_R with  was successfully processed.', 'A payment of TxnId - pay_7pay_Fpay_6pay_8pay_Mpay_Hpay_Ypay_Lpay_Fpay_8 with  was successfully processed.', 'Your recent transaction of TxnId - pay_Ypay_Opay_Wpay_Mpay_0pay_Vpay_7pay_Hpay_Epay_W with has been confirmed.', 'A withdrawal of TxnId - pay_6pay_Hpay_6pay_Cpay_Vpay_Hpay_Cpay_Dpay_4pay_Q witj has been completed from your account.', 'Your account has been credited with TxnId - pay_Npay_8pay_Spay_4pay_7pay_Opay_8pay_4pay_Hpay_5 with for a successful transaction.', 'Thank you for your payment of TxnId - pay_Upay_Xpay_Upay_Upay_Zpay_Ppay_Xpay_9pay_0pay_P with on our platform.', 'A refund of TxnId - pay_5pay_1pay_9pay_Bpay_Ppay_Ipay_Qpay_5pay_1pay_1 with has been initiated for your recent transaction.', 'Thank you for your payment of TxnId - pay_Epay_Npay_2pay_Kpay_Opay_6pay_7pay_5pay_Spay_C with on our platform.', 'Payment for  TxnId - pay_5pay_Fpay_9pay_Vpay_7pay_5pay_Qpay_5pay_Fpay_4.', 'A payment of TxnId - pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J with was declined. Please check your payment information.', 'Your account has been credited with TxnId - pay_5pay_Fpay_9pay_Vpay_7pay_5pay_Qpay_5pay_Fpay_4 with for a successful transaction.', 'A refund of TxnId - pay_Wpay_Jpay_Tpay_Wpay_0pay_Gpay_Bpay_Spay_Spay_C with has been initiated for your recent transaction.', '[\"IdCard\":\"TxnId - pay_Tpay_Gpay_Dpay_Ppay_Wpay_Gpay_Opay_Xpay_0pay_G\", \"message\":\"This is ID card\"]', 'Customer  Identity with TxnId - pay_Lpay_Ipay_Opay_Upay_Tpay_5pay_9pay_Gpay_Xpay_V.', 'A payment of TxnId - pay_Wpay_Jpay_Tpay_Wpay_0pay_Gpay_Bpay_Spay_Spay_C with  was successfully processed.', 'A refund of TxnId - pay_Gpay_Spay_Bpay_Ipay_Vpay_4pay_5pay_Ypay_Epay_6 with has been initiated for your recent transaction.', 'Transaction is successful for   TxnId - pay_1pay_Kpay_Fpay_4pay_Gpay_Bpay_6pay_Upay_Ipay_Q Payment', 'Your recent transaction of TxnId - pay_Fpay_Epay_Wpay_3pay_Vpay_Epay_Dpay_8pay_4pay_4 with has been confirmed.', \"This is a sample sentence that doesn't contain anything\", 'Payment for  TxnId - pay_7pay_7pay_Lpay_Npay_Jpay_Wpay_Opay_Jpay_Fpay_P.', 'Payment for  TxnId - pay_4pay_Zpay_Rpay_1pay_4pay_Hpay_8pay_Opay_Apay_0.', 'TxnId - pay_5pay_Opay_Npay_Kpay_Epay_6pay_Hpay_Mpay_Ipay_T with has been transferred to your linked bank account.', 'Customer  Identity with TxnId - pay_Rpay_7pay_Epay_Mpay_Gpay_8pay_7pay_Upay_Kpay_F.', 'TxnId - pay_Tpay_6pay_Ppay_Opay_Dpay_Vpay_5pay_Npay_4pay_T value for customer', 'Payment for  TxnId - pay_5pay_1pay_9pay_Bpay_Ppay_Ipay_Qpay_5pay_1pay_1.', 'A withdrawal of TxnId - pay_Kpay_0pay_Qpay_Wpay_2pay_Rpay_Ypay_Cpay_Mpay_N witj has been completed from your account.', 'Your credit card associated with TxnId - pay_Ppay_Zpay_Apay_7pay_Dpay_3pay_Npay_Epay_9pay_R has been charged', 'Customer  Identity with TxnId - pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J.', 'A payment of TxnId - pay_Dpay_3pay_Qpay_1pay_4pay_Mpay_Ppay_Kpay_Apay_7 with  was successfully processed.', \"This is a sample sentence that doesn't contain anything\", 'Your account has been credited with TxnId - pay_Apay_Apay_Ypay_Tpay_6pay_Zpay_Fpay_Epay_Fpay_B with for a successful transaction.', 'A payment of TxnId - pay_7pay_Fpay_6pay_8pay_Mpay_Hpay_Ypay_Lpay_Fpay_8 with  was successfully processed.', 'Your recent transaction of TxnId - pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J with has been confirmed.', 'The payment of TxnId - pay_Opay_Ipay_0pay_Upay_3pay_Xpay_Upay_Ipay_Mpay_K with was successful.', 'A payment of TxnId - pay_Wpay_Jpay_Tpay_Wpay_0pay_Gpay_Bpay_Spay_Spay_C with  was successfully processed.', 'TxnId - pay_Hpay_5pay_Wpay_Mpay_5pay_Gpay_7pay_Cpay_6pay_G value for customer', '[\"IdCard\":\"TxnId - pay_Rpay_Npay_3pay_Cpay_Hpay_Bpay_Vpay_Zpay_3pay_X\", \"message\":\"This is ID card\"]', '[\"IdCard\":\"TxnId - pay_3pay_Apay_1pay_0pay_2pay_3pay_Tpay_0pay_Apay_G\", \"message\":\"This is ID card\"]', 'Customer  Identity with TxnId - pay_6pay_Hpay_6pay_Cpay_Vpay_Hpay_Cpay_Dpay_4pay_Q.', 'A withdrawal of TxnId - pay_Tpay_Spay_2pay_0pay_Bpay_Xpay_4pay_6pay_1pay_X witj has been completed from your account.', 'A payment of TxnId - pay_Mpay_Cpay_Bpay_5pay_Fpay_4pay_Upay_Gpay_1pay_J with was declined. Please check your payment information.', 'Payment for  TxnId - pay_6pay_Hpay_6pay_Cpay_Vpay_Hpay_Cpay_Dpay_4pay_Q.', 'A refund of TxnId - pay_Tpay_0pay_2pay_Fpay_Dpay_Tpay_Kpay_3pay_Opay_G with has been initiated for your recent transaction.', 'TxnId - pay_Epay_9pay_1pay_Spay_Lpay_Ipay_Spay_Vpay_Ipay_J with has been transferred to your linked bank account.', 'Customer  Identity with TxnId - pay_5pay_Opay_Npay_Kpay_Epay_6pay_Hpay_Mpay_Ipay_T.', 'The payment of TxnId - pay_1pay_Lpay_Apay_4pay_Zpay_Fpay_Tpay_6pay_4pay_N with was successful.', 'Transaction is successful for   TxnId - pay_Rpay_Epay_Hpay_2pay_7pay_Rpay_Zpay_Lpay_Jpay_D Payment', 'Thank you for your payment of TxnId - pay_1pay_Lpay_Apay_4pay_Zpay_Fpay_Tpay_6pay_4pay_N with on our platform.', 'Thank you for your payment of TxnId - pay_3pay_Cpay_2pay_Mpay_8pay_Apay_Upay_Vpay_Mpay_6 with on our platform.', 'The payment of TxnId - pay_2pay_2pay_8pay_Rpay_Fpay_9pay_2pay_Ypay_Kpay_O with was successful.', 'A withdrawal of TxnId - pay_4pay_Npay_Mpay_Dpay_2pay_6pay_Kpay_Bpay_Ipay_H witj has been completed from your account.', \"This is a sample sentence that doesn't contain anything\", 'TxnId - pay_Dpay_3pay_Qpay_1pay_4pay_Mpay_Ppay_Kpay_Apay_7 with has been transferred to your linked bank account.', '[\"IdCard\":\"TxnId - pay_Tpay_Zpay_Cpay_Rpay_3pay_0pay_Upay_4pay_0pay_U\", \"message\":\"This is ID card\"]', 'A withdrawal of TxnId - pay_Ppay_Cpay_Kpay_Fpay_Ppay_Ipay_Opay_Ypay_Npay_I witj has been completed from your account.', 'A refund of TxnId - pay_5pay_Opay_Npay_Kpay_Epay_6pay_Hpay_Mpay_Ipay_T with has been initiated for your recent transaction.', 'Your account has been credited with TxnId - pay_4pay_Zpay_Rpay_1pay_4pay_Hpay_8pay_Opay_Apay_0 with for a successful transaction.', 'TxnId - pay_Tpay_Spay_2pay_0pay_Bpay_Xpay_4pay_6pay_1pay_X with has been transferred to your linked bank account.', 'Your recent transaction of TxnId - pay_Spay_Wpay_Lpay_Xpay_Tpay_Vpay_Tpay_Epay_Zpay_E with has been confirmed.', 'Transaction is successful for   TxnId - pay_1pay_Qpay_Ypay_Rpay_Upay_Ppay_Apay_7pay_Apay_4 Payment', 'Your account has been credited with TxnId - pay_5pay_Kpay_Lpay_Rpay_Tpay_Gpay_Wpay_Epay_2pay_T with for a successful transaction.', 'A refund of TxnId - pay_7pay_7pay_Lpay_Npay_Jpay_Wpay_Opay_Jpay_Fpay_P with has been initiated for your recent transaction.', 'Your recent transaction of TxnId - pay_1pay_0pay_Bpay_1pay_Upay_Spay_Rpay_Zpay_Upay_D with has been confirmed.', 'TxnId - pay_Upay_Xpay_Upay_Upay_Zpay_Ppay_Xpay_9pay_0pay_P value for customer', 'Your recent transaction of TxnId - pay_4pay_Vpay_Wpay_2pay_Epay_Ppay_Gpay_6pay_Dpay_F with has been confirmed.', 'Customer  Identity with TxnId - pay_1pay_0pay_Bpay_1pay_Upay_Spay_Rpay_Zpay_Upay_D.', 'The payment of TxnId - pay_Epay_Npay_2pay_Kpay_Opay_6pay_7pay_5pay_Spay_C with was successful.', 'Your account has been credited with TxnId - pay_5pay_Rpay_3pay_Mpay_Npay_Qpay_Fpay_2pay_5pay_R with for a successful transaction.', 'TxnId - pay_Rpay_7pay_Epay_Mpay_Gpay_8pay_7pay_Upay_Kpay_F value for customer', '[\"IdCard\":\"TxnId - pay_7pay_Dpay_Bpay_Fpay_3pay_Cpay_Tpay_Qpay_6pay_T\", \"message\":\"This is ID card\"]', 'Your recent transaction of TxnId - pay_Vpay_6pay_Vpay_Jpay_Fpay_Hpay_Bpay_Upay_Jpay_9 with has been confirmed.', '[\"IdCard\":\"TxnId - pay_Jpay_Apay_2pay_Lpay_Apay_Epay_Ppay_Epay_5pay_J\", \"message\":\"This is ID card\"]', 'Customer  Identity with Pancard - RCPKW1362U.', 'Thank you for your payment of Pancard - GRMAC2372U with on our platform.', 'Pancard - ENGJJ6735I value for customer', 'Your account has been credited with Pancard - UVQVJ9240H with for a successful transaction.', 'A payment of Pancard - YUFHM2264B with  was successfully processed.', 'The payment of Pancard - PMASV3467B with was successful.', 'Transaction is successful for   Pancard - ITMCL8549S Payment', 'Payment for  Pancard - GZHOQ9336R.', 'Your credit card associated with Pancard - FYMKQ6209M has been charged', 'Pancard - RJAWE9374H value for customer', 'Your account has been credited with Pancard - ITMCL8549S with for a successful transaction.', 'Thank you for your payment of Pancard - FVQOD4445G with on our platform.', 'Payment for  Pancard - OLSNW3508T.', 'Pancard - CSSSR1375Q value for customer', 'Customer  Identity with Pancard - BRMST2968T.', 'A refund of Pancard - MRAZO0803H with has been initiated for your recent transaction.', 'Your credit card associated with Pancard - OKDDS0624K has been charged', 'A payment of Pancard - VRZEK6387X with was declined. Please check your payment information.', 'Your credit card associated with Pancard - BTJNE5111Z has been charged', 'Thank you for your payment of Pancard - SDSQD1881O with on our platform.', 'A payment of Pancard - MRAZO0803H with was declined. Please check your payment information.', 'A payment of Pancard - ZOGIN9004E with was declined. Please check your payment information.', 'Pancard - LLJEN7852K with has been transferred to your linked bank account.', 'Your recent transaction of Pancard - BTJNE5111Z with has been confirmed.', 'A withdrawal of Pancard - YFOMW6318S witj has been completed from your account.', 'Your recent transaction of Pancard - LWCLY4973D with has been confirmed.', 'Transaction is successful for   Pancard - QBLGN5078W Payment', 'Customer  Identity with Pancard - YFOMW6318S.', 'Your recent transaction of Pancard - YUAZC4535I with has been confirmed.', 'Your recent transaction of Pancard - SHMKH8722U with has been confirmed.', 'A refund of Pancard - SDSQD1881O with has been initiated for your recent transaction.', 'A refund of Pancard - MCBIZ3407Z with has been initiated for your recent transaction.', 'A payment of Pancard - LWCLY4973D with  was successfully processed.', 'Payment for  Pancard - OKDDS0624K.', 'The payment of Pancard - PJZCF5819T with was successful.', 'The payment of Pancard - VLIOP6883D with was successful.', 'Your recent transaction of Pancard - LBBYC3829G with has been confirmed.', 'Your account has been credited with Pancard - YUINQ1328G with for a successful transaction.', 'Customer  Identity with Pancard - APZQR4209S.', 'Your account has been credited with Pancard - TTOHC4481C with for a successful transaction.', 'A refund of Pancard - RPFLI3888H with has been initiated for your recent transaction.', 'Transaction is successful for   Pancard - EOTJG8205T Payment', 'Transaction is successful for   Pancard - LVZGG8353K Payment', 'Your recent transaction of Pancard - YUFHM2264B with has been confirmed.', 'Your account has been credited with Pancard - LTTTX5672M with for a successful transaction.', 'A withdrawal of Pancard - LLJEN7852K witj has been completed from your account.', 'Thank you for your payment of Pancard - IFRKA7269O with on our platform.', 'Pancard - WYEYE0027E value for customer', 'Transaction is successful for   Pancard - YFOMW6318S Payment', 'A refund of Pancard - LVZGG8353K with has been initiated for your recent transaction.', 'A payment of Pancard - EOTJG8205T with was declined. Please check your payment information.', 'Your credit card associated with Pancard - UVQVJ9240H has been charged', 'A payment of Pancard - ENGJJ6735I with was declined. Please check your payment information.', 'Your account has been credited with Pancard - MRAZO0803H with for a successful transaction.', 'A refund of Pancard - IVCPW1636Y with has been initiated for your recent transaction.', 'Thank you for your payment of Pancard - YXIJB6036B with on our platform.', 'The payment of Pancard - ITMCL8549S with was successful.', '[\"IdCard\":\"Pancard - MKRKO2019L\", \"message\":\"This is ID card\"]', 'Transaction is successful for   Pancard - EIBVD0228N Payment', 'Pancard - YXIJB6036B with has been transferred to your linked bank account.', 'Transaction is successful for   Pancard - CMQFV8092F Payment', 'Pancard - PSYFQ4369F with has been transferred to your linked bank account.', 'Your recent transaction of Pancard - CMQFV8092F with has been confirmed.', 'Pancard - YUINQ1328G value for customer', '[\"IdCard\":\"Pancard - GZHOQ9336R\", \"message\":\"This is ID card\"]', 'Your account has been credited with Pancard - OSMCO7399N with for a successful transaction.', 'Pancard - QBLGN5078W value for customer', 'Your account has been credited with Pancard - FYMKQ6209M with for a successful transaction.', 'Your recent transaction of Pancard - OLSNW3508T with has been confirmed.', 'A payment of Pancard - GZHOQ9336R with was declined. Please check your payment information.', 'Thank you for your payment of Pancard - OKDDS0624K with on our platform.', 'Your recent transaction of Pancard - YHDPZ2396L with has been confirmed.', 'A payment of Pancard - IFRKA7269O with was declined. Please check your payment information.', 'Pancard - UVQVJ9240H with has been transferred to your linked bank account.', 'Transaction is successful for   Pancard - IEYPY6320S Payment', '[\"IdCard\":\"Pancard - ZOGIN9004E\", \"message\":\"This is ID card\"]', \"This is a sample sentence that doesn't contain anything\", 'A payment of Pancard - FXIDT5574B with  was successfully processed.', 'Thank you for your payment of Pancard - WYEYE0027E with on our platform.', 'Your account has been credited with Pancard - APZQR4209S with for a successful transaction.', 'Customer  Identity with Pancard - IFRKA7269O.', 'Customer  Identity with Pancard - PSYFQ4369F.', 'Payment for  Pancard - YUAZC4535I.', 'Your credit card associated with Pancard - LBBYC3829G has been charged', 'Your recent transaction of Pancard - FYMKQ6209M with has been confirmed.', 'Pancard - CMQFV8092F value for customer', 'The payment of Pancard - ZOGIN9004E with was successful.', '[\"IdCard\":\"Pancard - WYEYE0027E\", \"message\":\"This is ID card\"]', 'Your account has been credited with Pancard - XHQVY3673Y with for a successful transaction.', 'Thank you for your payment of Pancard - GHZXC2903S with on our platform.', 'Pancard - QMJTX6537M with has been transferred to your linked bank account.', 'Your credit card associated with Pancard - YAZZN3159P has been charged', 'The payment of Pancard - RPFLI3888H with was successful.', 'A refund of Pancard - RCPKW1362U with has been initiated for your recent transaction.', 'Pancard - MHSOZ1256G value for customer', '[\"IdCard\":\"Pancard - ZPDRZ5038L\", \"message\":\"This is ID card\"]', 'Your credit card associated with Pancard - QOWUQ6190H has been charged', 'Your recent transaction of Pancard - FAZQX4447O with has been confirmed.', 'Your account has been credited with Pancard - OSMCO7399N with for a successful transaction.', 'Transaction is successful for   Pancard - OAGOA4398Z Payment', 'Thank you for your payment of pancard with on our platform.', 'Payment for  aadhaar.', 'A payment of pancard with was declined. Please check your payment information.', \"This is a sample sentence that doesn't contain anything\", 'Transaction is successful for   aadhaar Payment', 'A withdrawal of pancard witj has been completed from your account.', 'pancard value for customer', 'pancard value for customer', 'A withdrawal of pancard witj has been completed from your account.', 'Payment for  pancard.', 'Your recent transaction of pancard with has been confirmed.', 'Customer  Identity with aadhaar.', 'A payment of pancard with was declined. Please check your payment information.', 'aadhaar value for customer', \"This is a sample sentence that doesn't contain anything\", 'Your recent transaction of aadhaar with has been confirmed.', 'A refund of aadhaar with has been initiated for your recent transaction.', \"This is a sample sentence that doesn't contain anything\", 'Thank you for your payment of aadhaar with on our platform.', '[\"IdCard\":\"aadhaar\", \"message\":\"This is ID card\"]', 'Your recent transaction of pancard with has been confirmed.', 'Payment for  pancard.', '[\"IdCard\":\"aadhaar\", \"message\":\"This is ID card\"]', 'Your recent transaction of pancard with has been confirmed.', 'A refund of aadhaar with has been initiated for your recent transaction.', 'Payment for  pancard.', 'A withdrawal of aadhaar witj has been completed from your account.', 'A payment of pancard with  was successfully processed.', 'A payment of pancard with was declined. Please check your payment information.', 'A refund of pancard with has been initiated for your recent transaction.', '[\"IdCard\":\"aadhaar\", \"message\":\"This is ID card\"]', 'Your account has been credited with aadhaar with for a successful transaction.', 'Payment for  aadhaar.', 'A refund of pancard with has been initiated for your recent transaction.', 'A withdrawal of aadhaar witj has been completed from your account.', 'aadhaar with has been transferred to your linked bank account.', '[\"IdCard\":\"pancard\", \"message\":\"This is ID card\"]', 'pancard value for customer', 'aadhaar value for customer', 'A payment of pancard with was declined. Please check your payment information.', 'A payment of pancard with was declined. Please check your payment information.', 'A payment of pancard with was declined. Please check your payment information.', 'Your account has been credited with pancard with for a successful transaction.', 'A payment of pancard with  was successfully processed.', 'A withdrawal of aadhaar witj has been completed from your account.', 'Your account has been credited with pancard with for a successful transaction.', 'pancard with has been transferred to your linked bank account.', 'A payment of pancard with  was successfully processed.', 'The payment of pancard with was successful.', 'A withdrawal of pancard witj has been completed from your account.', '[\"IdCard\":\"aadhaar\", \"message\":\"This is ID card\"]', 'Payment for  pancard.', 'Customer  Identity with aadhaar.', 'A payment of pancard with was declined. Please check your payment information.', 'Payment for  pancard.', 'Thank you for your payment of aadhaar with on our platform.', 'pancard value for customer', 'Your recent transaction of pancard with has been confirmed.', 'Thank you for your payment of pancard with on our platform.', 'Customer  Identity with pancard.', 'aadhaar value for customer', 'Payment for  pancard.', 'Your credit card associated with pancard has been charged', '[\"IdCard\":\"aadhaar\", \"message\":\"This is ID card\"]', 'A refund of aadhaar with has been initiated for your recent transaction.', 'A payment of aadhaar with  was successfully processed.', 'Your credit card associated with aadhaar has been charged', '[\"IdCard\":\"pancard\", \"message\":\"This is ID card\"]', 'A withdrawal of aadhaar witj has been completed from your account.', 'Thank you for your payment of aadhaar with on our platform.', 'pancard value for customer', 'A payment of aadhaar with was declined. Please check your payment information.', 'Your recent transaction of pancard with has been confirmed.', 'A payment of aadhaar with was declined. Please check your payment information.', 'The payment of pancard with was successful.', 'A payment of pancard with  was successfully processed.', 'Transaction is successful for   aadhaar Payment', 'The payment of aadhaar with was successful.', 'A withdrawal of pancard witj has been completed from your account.', 'A refund of pancard with has been initiated for your recent transaction.', 'Your credit card associated with pancard has been charged', 'A withdrawal of aadhaar witj has been completed from your account.', 'Customer  Identity with aadhaar.', 'The payment of aadhaar with was successful.', 'A refund of pancard with has been initiated for your recent transaction.', 'aadhaar value for customer', 'Thank you for your payment of pancard with on our platform.', 'Transaction is successful for   pancard Payment', 'Customer  Identity with aadhaar.', 'pancard with has been transferred to your linked bank account.', 'aadhaar value for customer', 'The payment of pancard with was successful.', '[\"IdCard\":\"aadhaar\", \"message\":\"This is ID card\"]', 'A payment of aadhaar with  was successfully processed.', 'aadhaar with has been transferred to your linked bank account.', 'A payment of pancard with  was successfully processed.', 'Thank you for your payment of aadhaar with on our platform.', 'Your account has been credited with pancard with for a successful transaction.', 'aadhaar with has been transferred to your linked bank account.', \"This is a sample sentence that doesn't contain anything\"]\n",
            "['544711972165', '245305408565', '163535239514', '951069542219', '006558100054', '757267350918', '040169356874', '659570810275', '272070156403', '189478304954', '056745090399', '473995216470', '279930153992', '951069542219', '617876456949', '951069542219', '759969645667', '633722613065', '053826108247', '163746400979', '898518679267', '753051834914', '041890409687', '006558100054', '040169356874', '965438428080', '579258430618', '970199177698', '544256902836', '694975789293', '061898529654', '753051834914', '189478304954', '370932388994', '747364494365', '633722613065', '844251250207', '544256902836', '491577364220', '933520977398', '053826108247', '370932388994', '189478304954', '831262153393', '753051834914', '506929123020', '277870639977', '853890926126', '524717252485', '685988120650', '513583102881', '053826108247', '045746375137', '992570017394', '797363744822', '170936389018', '006558100054', '903050016469', '757267350918', '100212849209', '282275206888', '437789283396', '627784150213', '544711972165', '797363744822', '844251250207', '559027355091', '797363744822', '452447415802', '277870639977', '120969773372', '279930153992', '491577364220', '524717252485', '605234610007', '992570017394', '437789283396', '514834794884', '957572407421', '041890409687', '070315937070', '965438428080', '294455844602', '544711972165', '559027355091', '247548236221', '437789283396', '975210172288', '287614794573', '120514924235', '284067236232', '277870639977', '301690130441', '326503906842', '514834794884', '579258430618', '084445399817', '831262153393', '472073193687', '513818685263', 'pay_Hpay_5pay_Wpay_Mpay_5pay_Gpay_7pay_Cpay_6pay_G', 'pay_Mpay_1pay_Hpay_Ypay_0pay_1pay_Tpay_Jpay_7pay_O', 'pay_Fpay_Epay_Wpay_3pay_Vpay_Epay_Dpay_8pay_4pay_4', 'pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J', 'pay_Gpay_Spay_Bpay_Ipay_Vpay_4pay_5pay_Ypay_Epay_6', 'pay_9pay_Ppay_Lpay_Vpay_Wpay_Upay_Rpay_0pay_Gpay_1', 'pay_2pay_2pay_8pay_Rpay_Fpay_9pay_2pay_Ypay_Kpay_O', 'pay_Fpay_Fpay_Rpay_Gpay_Tpay_7pay_Ipay_Spay_Cpay_L', 'pay_Dpay_Cpay_Epay_Hpay_8pay_Xpay_9pay_Xpay_Dpay_2', 'pay_Rpay_Epay_Hpay_2pay_7pay_Rpay_Zpay_Lpay_Jpay_D', 'pay_5pay_Rpay_3pay_Mpay_Npay_Qpay_Fpay_2pay_5pay_R', 'pay_2pay_6pay_6pay_Hpay_Ypay_9pay_Dpay_Upay_Rpay_L', 'pay_Tpay_Gpay_Dpay_Ppay_Wpay_Gpay_Opay_Xpay_0pay_G', 'pay_Jpay_Dpay_4pay_Qpay_Rpay_Cpay_Zpay_Xpay_Upay_V', 'pay_Dpay_9pay_Vpay_Epay_5pay_Tpay_2pay_Spay_2pay_2', 'pay_6pay_Upay_Ppay_Cpay_Dpay_1pay_3pay_7pay_Apay_0', 'pay_9pay_Qpay_Lpay_Spay_Lpay_Jpay_Qpay_Spay_Ypay_6', 'pay_Tpay_Zpay_Cpay_Rpay_3pay_0pay_Upay_4pay_0pay_U', 'pay_4pay_Npay_Mpay_Dpay_2pay_6pay_Kpay_Bpay_Ipay_H', 'pay_1pay_Lpay_Apay_4pay_Zpay_Fpay_Tpay_6pay_4pay_N', 'pay_Rpay_Epay_Hpay_2pay_7pay_Rpay_Zpay_Lpay_Jpay_D', 'pay_Vpay_Mpay_Ipay_2pay_Zpay_6pay_Wpay_Xpay_Epay_H', 'pay_3pay_3pay_Ppay_Hpay_Rpay_Upay_Ipay_Dpay_0pay_X', 'pay_Ppay_Epay_Rpay_Npay_Lpay_2pay_4pay_Ppay_1pay_0', 'pay_Vpay_Wpay_Xpay_Opay_Ppay_Lpay_7pay_Spay_2pay_5', 'pay_7pay_7pay_Lpay_Npay_Jpay_Wpay_Opay_Jpay_Fpay_P', 'pay_6pay_Hpay_Opay_Hpay_Cpay_6pay_2pay_0pay_Qpay_Y', 'pay_Mpay_1pay_Hpay_Ypay_0pay_1pay_Tpay_Jpay_7pay_O', 'pay_9pay_1pay_4pay_6pay_9pay_Mpay_Gpay_Zpay_Ipay_R', 'pay_7pay_Fpay_6pay_8pay_Mpay_Hpay_Ypay_Lpay_Fpay_8', 'pay_Ypay_Opay_Wpay_Mpay_0pay_Vpay_7pay_Hpay_Epay_W', 'pay_6pay_Hpay_6pay_Cpay_Vpay_Hpay_Cpay_Dpay_4pay_Q', 'pay_Npay_8pay_Spay_4pay_7pay_Opay_8pay_4pay_Hpay_5', 'pay_Upay_Xpay_Upay_Upay_Zpay_Ppay_Xpay_9pay_0pay_P', 'pay_5pay_1pay_9pay_Bpay_Ppay_Ipay_Qpay_5pay_1pay_1', 'pay_Epay_Npay_2pay_Kpay_Opay_6pay_7pay_5pay_Spay_C', 'pay_5pay_Fpay_9pay_Vpay_7pay_5pay_Qpay_5pay_Fpay_4', 'pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J', 'pay_5pay_Fpay_9pay_Vpay_7pay_5pay_Qpay_5pay_Fpay_4', 'pay_Wpay_Jpay_Tpay_Wpay_0pay_Gpay_Bpay_Spay_Spay_C', 'pay_Tpay_Gpay_Dpay_Ppay_Wpay_Gpay_Opay_Xpay_0pay_G', 'pay_Lpay_Ipay_Opay_Upay_Tpay_5pay_9pay_Gpay_Xpay_V', 'pay_Wpay_Jpay_Tpay_Wpay_0pay_Gpay_Bpay_Spay_Spay_C', 'pay_Gpay_Spay_Bpay_Ipay_Vpay_4pay_5pay_Ypay_Epay_6', 'pay_1pay_Kpay_Fpay_4pay_Gpay_Bpay_6pay_Upay_Ipay_Q', 'pay_Fpay_Epay_Wpay_3pay_Vpay_Epay_Dpay_8pay_4pay_4', 'pay_4pay_Zpay_Rpay_1pay_4pay_Hpay_8pay_Opay_Apay_0', 'pay_7pay_7pay_Lpay_Npay_Jpay_Wpay_Opay_Jpay_Fpay_P', 'pay_4pay_Zpay_Rpay_1pay_4pay_Hpay_8pay_Opay_Apay_0', 'pay_5pay_Opay_Npay_Kpay_Epay_6pay_Hpay_Mpay_Ipay_T', 'pay_Rpay_7pay_Epay_Mpay_Gpay_8pay_7pay_Upay_Kpay_F', 'pay_Tpay_6pay_Ppay_Opay_Dpay_Vpay_5pay_Npay_4pay_T', 'pay_5pay_1pay_9pay_Bpay_Ppay_Ipay_Qpay_5pay_1pay_1', 'pay_Kpay_0pay_Qpay_Wpay_2pay_Rpay_Ypay_Cpay_Mpay_N', 'pay_Ppay_Zpay_Apay_7pay_Dpay_3pay_Npay_Epay_9pay_R', 'pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J', 'pay_Dpay_3pay_Qpay_1pay_4pay_Mpay_Ppay_Kpay_Apay_7', 'pay_Bpay_Cpay_Fpay_Ipay_Ipay_Npay_Bpay_5pay_Hpay_0', 'pay_Apay_Apay_Ypay_Tpay_6pay_Zpay_Fpay_Epay_Fpay_B', 'pay_7pay_Fpay_6pay_8pay_Mpay_Hpay_Ypay_Lpay_Fpay_8', 'pay_Kpay_Dpay_Mpay_6pay_9pay_Cpay_Ipay_Tpay_2pay_J', 'pay_Opay_Ipay_0pay_Upay_3pay_Xpay_Upay_Ipay_Mpay_K', 'pay_Wpay_Jpay_Tpay_Wpay_0pay_Gpay_Bpay_Spay_Spay_C', 'pay_Hpay_5pay_Wpay_Mpay_5pay_Gpay_7pay_Cpay_6pay_G', 'pay_Rpay_Npay_3pay_Cpay_Hpay_Bpay_Vpay_Zpay_3pay_X', 'pay_3pay_Apay_1pay_0pay_2pay_3pay_Tpay_0pay_Apay_G', 'pay_6pay_Hpay_6pay_Cpay_Vpay_Hpay_Cpay_Dpay_4pay_Q', 'pay_Tpay_Spay_2pay_0pay_Bpay_Xpay_4pay_6pay_1pay_X', 'pay_Mpay_Cpay_Bpay_5pay_Fpay_4pay_Upay_Gpay_1pay_J', 'pay_6pay_Hpay_6pay_Cpay_Vpay_Hpay_Cpay_Dpay_4pay_Q', 'pay_Tpay_0pay_2pay_Fpay_Dpay_Tpay_Kpay_3pay_Opay_G', 'pay_Epay_9pay_1pay_Spay_Lpay_Ipay_Spay_Vpay_Ipay_J', 'pay_5pay_Opay_Npay_Kpay_Epay_6pay_Hpay_Mpay_Ipay_T', 'pay_1pay_Lpay_Apay_4pay_Zpay_Fpay_Tpay_6pay_4pay_N', 'pay_Rpay_Epay_Hpay_2pay_7pay_Rpay_Zpay_Lpay_Jpay_D', 'pay_1pay_Lpay_Apay_4pay_Zpay_Fpay_Tpay_6pay_4pay_N', 'pay_3pay_Cpay_2pay_Mpay_8pay_Apay_Upay_Vpay_Mpay_6', 'pay_2pay_2pay_8pay_Rpay_Fpay_9pay_2pay_Ypay_Kpay_O', 'pay_4pay_Npay_Mpay_Dpay_2pay_6pay_Kpay_Bpay_Ipay_H', 'pay_Tpay_Ypay_Jpay_Fpay_8pay_0pay_Kpay_5pay_Xpay_P', 'pay_Dpay_3pay_Qpay_1pay_4pay_Mpay_Ppay_Kpay_Apay_7', 'pay_Tpay_Zpay_Cpay_Rpay_3pay_0pay_Upay_4pay_0pay_U', 'pay_Ppay_Cpay_Kpay_Fpay_Ppay_Ipay_Opay_Ypay_Npay_I', 'pay_5pay_Opay_Npay_Kpay_Epay_6pay_Hpay_Mpay_Ipay_T', 'pay_4pay_Zpay_Rpay_1pay_4pay_Hpay_8pay_Opay_Apay_0', 'pay_Tpay_Spay_2pay_0pay_Bpay_Xpay_4pay_6pay_1pay_X', 'pay_Spay_Wpay_Lpay_Xpay_Tpay_Vpay_Tpay_Epay_Zpay_E', 'pay_1pay_Qpay_Ypay_Rpay_Upay_Ppay_Apay_7pay_Apay_4', 'pay_5pay_Kpay_Lpay_Rpay_Tpay_Gpay_Wpay_Epay_2pay_T', 'pay_7pay_7pay_Lpay_Npay_Jpay_Wpay_Opay_Jpay_Fpay_P', 'pay_1pay_0pay_Bpay_1pay_Upay_Spay_Rpay_Zpay_Upay_D', 'pay_Upay_Xpay_Upay_Upay_Zpay_Ppay_Xpay_9pay_0pay_P', 'pay_4pay_Vpay_Wpay_2pay_Epay_Ppay_Gpay_6pay_Dpay_F', 'pay_1pay_0pay_Bpay_1pay_Upay_Spay_Rpay_Zpay_Upay_D', 'pay_Epay_Npay_2pay_Kpay_Opay_6pay_7pay_5pay_Spay_C', 'pay_5pay_Rpay_3pay_Mpay_Npay_Qpay_Fpay_2pay_5pay_R', 'pay_Rpay_7pay_Epay_Mpay_Gpay_8pay_7pay_Upay_Kpay_F', 'pay_7pay_Dpay_Bpay_Fpay_3pay_Cpay_Tpay_Qpay_6pay_T', 'pay_Vpay_6pay_Vpay_Jpay_Fpay_Hpay_Bpay_Upay_Jpay_9', 'pay_Jpay_Apay_2pay_Lpay_Apay_Epay_Ppay_Epay_5pay_J', 'RCPKW1362U', 'GRMAC2372U', 'ENGJJ6735I', 'UVQVJ9240H', 'YUFHM2264B', 'PMASV3467B', 'ITMCL8549S', 'GZHOQ9336R', 'FYMKQ6209M', 'RJAWE9374H', 'ITMCL8549S', 'FVQOD4445G', 'OLSNW3508T', 'CSSSR1375Q', 'BRMST2968T', 'MRAZO0803H', 'OKDDS0624K', 'VRZEK6387X', 'BTJNE5111Z', 'SDSQD1881O', 'MRAZO0803H', 'ZOGIN9004E', 'LLJEN7852K', 'BTJNE5111Z', 'YFOMW6318S', 'LWCLY4973D', 'QBLGN5078W', 'YFOMW6318S', 'YUAZC4535I', 'SHMKH8722U', 'SDSQD1881O', 'MCBIZ3407Z', 'LWCLY4973D', 'OKDDS0624K', 'PJZCF5819T', 'VLIOP6883D', 'LBBYC3829G', 'YUINQ1328G', 'APZQR4209S', 'TTOHC4481C', 'RPFLI3888H', 'EOTJG8205T', 'LVZGG8353K', 'YUFHM2264B', 'LTTTX5672M', 'LLJEN7852K', 'IFRKA7269O', 'WYEYE0027E', 'YFOMW6318S', 'LVZGG8353K', 'EOTJG8205T', 'UVQVJ9240H', 'ENGJJ6735I', 'MRAZO0803H', 'IVCPW1636Y', 'YXIJB6036B', 'ITMCL8549S', 'MKRKO2019L', 'EIBVD0228N', 'YXIJB6036B', 'CMQFV8092F', 'PSYFQ4369F', 'CMQFV8092F', 'YUINQ1328G', 'GZHOQ9336R', 'OSMCO7399N', 'QBLGN5078W', 'FYMKQ6209M', 'OLSNW3508T', 'GZHOQ9336R', 'OKDDS0624K', 'YHDPZ2396L', 'IFRKA7269O', 'UVQVJ9240H', 'IEYPY6320S', 'ZOGIN9004E', 'YUFHM2264B', 'FXIDT5574B', 'WYEYE0027E', 'APZQR4209S', 'IFRKA7269O', 'PSYFQ4369F', 'YUAZC4535I', 'LBBYC3829G', 'FYMKQ6209M', 'CMQFV8092F', 'ZOGIN9004E', 'WYEYE0027E', 'XHQVY3673Y', 'GHZXC2903S', 'QMJTX6537M', 'YAZZN3159P', 'RPFLI3888H', 'RCPKW1362U', 'MHSOZ1256G', 'ZPDRZ5038L', 'QOWUQ6190H', 'FAZQX4447O', 'OSMCO7399N', 'OAGOA4398Z', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "fake_ = Fake_PII()\n",
        "data = fake_.create_fake_profile(100,verbose=True)\n",
        "# print(data['AadhaarNumber'])\n",
        "# print(data['PanCard'])\n",
        "train_labels, train_text, train_PII = fake_.create_pii_text_train(n_text = 100)\n",
        "for i, element in enumerate(train_labels):\n",
        "  if element == 'Aadhaar' or element == 'Pancard':\n",
        "    train_labels[i]= \"PII\"\n",
        "print(train_labels)\n",
        "print(train_text)\n",
        "print(train_PII)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmrndk4zrOEl",
        "outputId": "898b1fe7-936c-41eb-f703-dd8bd5ec4af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.56\n",
            "  Training epoch took: 00:00:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 00:00:34\n",
            "\n",
            "Evaluation on test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.75      0.84        36\n",
            "           1       0.83      0.98      0.90        44\n",
            "\n",
            "    accuracy                           0.88        80\n",
            "   macro avg       0.90      0.86      0.87        80\n",
            "weighted avg       0.89      0.88      0.87        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "# Function to format elapsed time\n",
        "import time\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_rounded)))\n",
        "# Sample dataset (replace this with your actual dataset)\n",
        "data = {\n",
        "    'sentence': train_text,\n",
        "    'label': train_labels\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['sentence'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Tokenize inputs\n",
        "def tokenize_inputs(text_list, tokenizer, max_length):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in text_list:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_length,           # Pad & truncate all sentences.\n",
        "                            padding='max_length',\n",
        "                            truncation=True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                       )\n",
        "\n",
        "        # Add the encoded sentence to the list.\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Tokenize training and testing data\n",
        "train_input_ids, train_attention_masks = tokenize_inputs(X_train, tokenizer, max_length=128)\n",
        "test_input_ids, test_attention_masks = tokenize_inputs(X_test, tokenizer, max_length=128)\n",
        "\n",
        "# Convert labels to torch tensors\n",
        "train_labels = torch.tensor([1 if label == 'PII' else 0 for label in y_train])\n",
        "test_labels = torch.tensor([1 if label == 'PII' else 0 for label in y_test])\n",
        "\n",
        "# Prepare DataLoader\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "# Training\n",
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print('Training on', device)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    t0 = time.time()\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in test_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "\n",
        "\n",
        "# Evaluation on test set\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        preds = np.argmax(logits, axis=1)\n",
        "\n",
        "        all_labels.extend(label_ids)\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "\n",
        "# Evaluation on test set\n",
        "print(\"\\nEvaluation on test set:\")\n",
        "evaluate(model, test_dataloader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYAKhzQhvizG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a239b913-5e85-4ed2-ef58-471bc97ee80d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detected labels for sample sentences:\n",
            "\n",
            "\n",
            "Sentence: 'Customer with Aadhaar number 5828 9552 3855 is requesting a transaction.'\n",
            "Label : PII\n",
            "Custom entities: [('Aadhaar', '5828 9552 3855')]\n",
            "Redacted text: Customer with Aadhaar number [REDACTED] is requesting a transaction.\n",
            "\n",
            "Sentence: 'Amount:$100 with TxnID:pay_NXDEFGHAS'\n",
            "Label : Other\n",
            "\n",
            "Sentence: 'Pancard: ABCDE1234F belongs to the account holder.'\n",
            "Label : PII\n",
            "Custom entities: [('PanCard', 'ABCDE1234F')]\n",
            "Redacted text: Pancard: [REDACTED] belongs to the account holder.\n",
            "\n",
            "Sentence: 'KYC verification successful for customer with Aadhaar number 9876 5432 1098.'\n",
            "Label : PII\n",
            "Custom entities: [('Aadhaar', '9876 5432 1098')]\n",
            "Redacted text: KYC verification successful for customer with Aadhaar number [REDACTED].\n",
            "\n",
            "Sentence: 'Invalid transaction. Please check your details.'\n",
            "Label : PII\n",
            "Custom entities: []\n",
            "Redacted text: Invalid transaction. Please check your details.\n",
            "\n",
            "Sentence: 'Pancard number XYZAB5678G is invalid.'\n",
            "Label : PII\n",
            "Custom entities: [('PanCard', 'XYZAB5678G')]\n",
            "Redacted text: Pancard number [REDACTED] is invalid.\n",
            "\n",
            "Sentence: 'Customer with Aadhaar num 987654321098 is requesting a transaction.'\n",
            "Label : PII\n",
            "Custom entities: [('Aadhaar', '987654321098')]\n",
            "Redacted text: Customer with Aadhaar num [REDACTED] is requesting a transaction.\n",
            "\n",
            "Sentence: 'Pancard: XYZAB5678G belongs to the account holder.'\n",
            "Label : PII\n",
            "Custom entities: [('PanCard', 'XYZAB5678G')]\n",
            "Redacted text: Pancard: [REDACTED] belongs to the account holder.\n",
            "\n",
            "Sentence: 'Wow My PanCard Number is Amazing and AadhaarCard Number is also Amazing'\n",
            "Label : PII\n",
            "Custom entities: []\n",
            "Redacted text: Wow My PanCard Number is Amazing and AadhaarCard Number is also Amazing\n",
            "\n",
            "Sentence: 'A refund of Aadhaar - 763285734061 with has been initiated for your recent transaction.'\n",
            "Label : PII\n",
            "Custom entities: [('Aadhaar', '763285734061')]\n",
            "Redacted text: A refund of Aadhaar - [REDACTED] with has been initiated for your recent transaction.\n",
            "\n",
            "Sentence: 'This is a sample sentence that doesn't contain anything'\n",
            "Label : Other\n",
            "\n",
            "Sentence: 'Thank you for paying with DQEPP8752A'\n",
            "Label : PII\n",
            "Custom entities: [('PanCard', 'DQEPP8752A')]\n",
            "Redacted text: Thank you for paying with [REDACTED]\n",
            "\n",
            "Sentence: 'Thank you for paying with Pancard:DQEPP8752A'\n",
            "Label : PII\n",
            "Custom entities: [('PanCard', 'DQEPP8752A')]\n",
            "Redacted text: Thank you for paying with Pancard:[REDACTED]\n",
            "\n",
            "Sentence: '{\"PanCard\":\"XYZAB5678G\", \"message\":\"This is ID card\"}'\n",
            "Label : PII\n",
            "Custom entities: [('PanCard', 'XYZAB5678G')]\n",
            "Redacted text: {\"PanCard\":\"[REDACTED]\", \"message\":\"This is ID card\"}\n",
            "\n",
            "Sentence: '{\"aadhaarNumber\":\"694361360105\", \"message\":\"This is ID card\"}'\n",
            "Label : PII\n",
            "Custom entities: [('Aadhaar', '694361360105')]\n",
            "Redacted text: {\"aadhaarNumber\":\"[REDACTED]\", \"message\":\"This is ID card\"}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "# Function to detect sensitive information using the trained BERT model\n",
        "def detect_sensitive_info_bert(model, tokenizer, sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=1000, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    #print(predicted_class)\n",
        "    return \"PII\" if predicted_class == 1 else \"Other\"\n",
        "\n",
        "# Test with sample sentences\n",
        "sample_sentences = [\n",
        "    \"Customer with Aadhaar number 5828 9552 3855 is requesting a transaction.\",\n",
        "    \"Amount:$100 with TxnID:pay_NXDEFGHAS\",\n",
        "    \"Pancard: ABCDE1234F belongs to the account holder.\",\n",
        "    \"KYC verification successful for customer with Aadhaar number 9876 5432 1098.\",\n",
        "    \"Invalid transaction. Please check your details.\",\n",
        "    \"Pancard number XYZAB5678G is invalid.\",\n",
        "    \"Customer with Aadhaar num 987654321098 is requesting a transaction.\",\n",
        "    \"Pancard: XYZAB5678G belongs to the account holder.\",\n",
        "    \"Wow My PanCard Number is Amazing and AadhaarCard Number is also Amazing\",\n",
        "    \"A refund of Aadhaar - 763285734061 with has been initiated for your recent transaction.\",\n",
        "    \"This is a sample sentence that doesn't contain anything\",\n",
        "    \"Thank you for paying with DQEPP8752A\",\n",
        "    \"Thank you for paying with Pancard:DQEPP8752A\",\n",
        "    '{\"PanCard\":\"XYZAB5678G\", \"message\":\"This is ID card\"}',\n",
        "    '{\"aadhaarNumber\":\"694361360105\", \"message\":\"This is ID card\"}'\n",
        "]\n",
        "\n",
        "def extract_custom_entities(text):\n",
        "    # Define regular expressions for Aadhaar card and Pan card patterns\n",
        "    aadhaar_pattern = r'\\b\\d{4}\\s?\\d{4}\\s?\\d{4}\\b'  # Aadhaar card pattern\n",
        "    pancard_pattern = r'[A-Z]{5}\\d{4}[A-Z]'         # Pan card pattern\n",
        "\n",
        "    # Search for Aadhaar card numbers and Pan card numbers in the text\n",
        "    aadhaar_matches = re.findall(aadhaar_pattern, text)\n",
        "    pancard_matches = re.findall(pancard_pattern, text)\n",
        "\n",
        "    # Combine the matches and their labels\n",
        "    custom_entities = [(\"Aadhaar\", match) for match in aadhaar_matches]\n",
        "    custom_entities += [(\"PanCard\", match) for match in pancard_matches]\n",
        "\n",
        "    return custom_entities\n",
        "\n",
        "def redact_custom_entities(text):\n",
        "    # Define regular expressions for Aadhaar card and Pan card patterns\n",
        "    aadhaar_pattern = r'\\b\\d{4}\\s?\\d{4}\\s?\\d{4}\\b'  # Aadhaar card pattern\n",
        "    pancard_pattern = r'[A-Z]{5}\\d{4}[A-Z]'         # Pan card pattern\n",
        "\n",
        "    # Redact Aadhaar card numbers\n",
        "    redacted_text = re.sub(aadhaar_pattern, \"[REDACTED]\", text)\n",
        "\n",
        "    # Redact Pan card numbers\n",
        "    redacted_text = re.sub(pancard_pattern, \"[REDACTED]\", redacted_text)\n",
        "\n",
        "    return redacted_text\n",
        "\n",
        "print(\"\\nDetected labels for sample sentences:\\n\")\n",
        "for sentence in sample_sentences:\n",
        "    label = detect_sensitive_info_bert(model, tokenizer, sentence)\n",
        "    print(f\"\\nSentence: '{sentence}'\\nLabel : {label}\")\n",
        "    if label == 'PII':\n",
        "      entities = extract_custom_entities(sentence)\n",
        "      print(\"Custom entities:\", entities)\n",
        "      redacted_text = redact_custom_entities(sentence)\n",
        "      print(\"Redacted text:\", redacted_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_to_log(data_list, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        for item in data_list:\n",
        "            file.write(str(item) + '\\n')\n",
        "\n",
        "def read_from_log(filename):\n",
        "    data_list = []\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            data_list.append(line.strip())\n",
        "    return data_list\n",
        "\n",
        "train_labels, train_text, train_PII = fake_.create_pii_text_train(n_text = 100)\n",
        "\n",
        "write_to_log(train_text, 'application.log')\n",
        "datalist = read_from_log('application.log')\n",
        "list_redacted=[]\n",
        "for sentence in datalist:\n",
        "    label = detect_sensitive_info_bert(model, tokenizer, sentence)\n",
        "    #print(f\"\\nSentence: '{sentence}'\\nLabel : {label}\")\n",
        "    if label == 'PII':\n",
        "      entities = extract_custom_entities(sentence)\n",
        "      redacted_text = redact_custom_entities(sentence)\n",
        "      list_redacted.append(redacted_text)\n",
        "write_to_log(list_redacted, 'application_redacted.log')\n",
        "print('Completed')\n"
      ],
      "metadata": {
        "id": "1EOQ_2m3lJTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c138b43c-5751-4e17-b43f-d104544920bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:00<00:00, 16327.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'binary_model.pth')"
      ],
      "metadata": {
        "id": "8CRyLFIxArSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import re\n",
        "# Function to detect sensitive information using the trained BERT model\n",
        "def detect_sensitive_info_bert(model, tokenizer, sentence):\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=1000, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    #print(predicted_class)\n",
        "    return \"PII\" if predicted_class == 1 else \"Other\"\n",
        "\n",
        "\n",
        "\n",
        "def extract_custom_entities(text):\n",
        "    # Define regular expressions for Aadhaar card and Pan card patterns\n",
        "    aadhaar_pattern = r'\\b\\d{4}\\s?\\d{4}\\s?\\d{4}\\b'  # Aadhaar card pattern\n",
        "    pancard_pattern = r'[A-Z]{5}\\d{4}[A-Z]'         # Pan card pattern\n",
        "\n",
        "    # Search for Aadhaar card numbers and Pan card numbers in the text\n",
        "    aadhaar_matches = re.findall(aadhaar_pattern, text)\n",
        "    pancard_matches = re.findall(pancard_pattern, text)\n",
        "\n",
        "    # Combine the matches and their labels\n",
        "    custom_entities = [(\"Aadhaar\", match) for match in aadhaar_matches]\n",
        "    custom_entities += [(\"PanCard\", match) for match in pancard_matches]\n",
        "\n",
        "    return custom_entities\n",
        "\n",
        "def redact_custom_entities(text):\n",
        "    # Define regular expressions for Aadhaar card and Pan card patterns\n",
        "    aadhaar_pattern = r'\\b\\d{4}\\s?\\d{4}\\s?\\d{4}\\b'  # Aadhaar card pattern\n",
        "    pancard_pattern = r'[A-Z]{5}\\d{4}[A-Z]'         # Pan card pattern\n",
        "\n",
        "    # Redact Aadhaar card numbers\n",
        "    redacted_text = re.sub(aadhaar_pattern, \"[REDACTED]\", text)\n",
        "\n",
        "    # Redact Pan card numbers\n",
        "    redacted_text = re.sub(pancard_pattern, \"[REDACTED]\", redacted_text)\n",
        "\n",
        "    return redacted_text\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the saved state dictionary\n",
        "state_dict = torch.load('binary_model.pth')\n",
        "\n",
        "# Initialize the model with the saved state dictionary\n",
        "model.load_state_dict(state_dict)\n",
        "label=''\n",
        "# Define the Streamlit application\n",
        "def main():\n",
        "    st.title(\"Strengthening Log Security: PII & Sensitive Data Identification and Masking - Demo\")\n",
        "    # Add an input textarea for text input\n",
        "    input_text = st.text_area(\"Enter Log Text:\")\n",
        "    label = detect_sensitive_info_bert(model, tokenizer, input_text)\n",
        "    st.write(f\"\\nSentence: '{input_text}'\\nLabel : {label}\")\n",
        "    if label == 'PII':\n",
        "      entities = extract_custom_entities(input_text)\n",
        "      st.write(\"Custom entities:\", entities)\n",
        "      redacted_text = redact_custom_entities(input_text)\n",
        "      st.write(\"Redacted text:\", redacted_text)\n",
        "\n",
        "# Run the Streamlit app\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2KPOsazArxd",
        "outputId": "58c6891c-4678-4ea3-e576-81165168ce32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & > logs.txt & npx localtunnel --port 8501 & curl https://loca.lt/mytunnelpassword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvZvOCWyWuRl",
        "outputId": "504715dd-ee77-4d20-b128-263e65af4587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.141.159.227\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.141.159.227:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.118s\n",
            "your url is: https://green-things-yawn.loca.lt\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/root/.npm/_npx/21473/lib/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:36045 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/21473/lib/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (events.js:315:20)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (internal/streams/destroy.js:106:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (internal/streams/destroy.js:74:3)\u001b[39m\n",
            "\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7UdPdemFY2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJP+uoBwxras6CI9aHB5Wn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}